{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9594998,"sourceType":"datasetVersion","datasetId":5852820},{"sourceId":9610692,"sourceType":"datasetVersion","datasetId":5864287}],"dockerImageVersionId":30787,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-12T18:36:35.164711Z","iopub.execute_input":"2024-10-12T18:36:35.165026Z","iopub.status.idle":"2024-10-12T18:36:36.168747Z","shell.execute_reply.started":"2024-10-12T18:36:35.164991Z","shell.execute_reply":"2024-10-12T18:36:36.167824Z"},"trusted":true},"outputs":[{"name":"stdout","text":"/kaggle/input/cleaned-amazon-reviews/cleaned_amazon_reviews.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-12T21:27:25.373937Z","iopub.execute_input":"2024-10-12T21:27:25.374781Z","iopub.status.idle":"2024-10-12T21:27:25.378804Z","shell.execute_reply.started":"2024-10-12T21:27:25.374740Z","shell.execute_reply":"2024-10-12T21:27:25.377846Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport tensorflow as tf\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.preprocessing.text import Tokenizer","metadata":{"execution":{"iopub.status.busy":"2024-10-12T21:20:16.519164Z","iopub.execute_input":"2024-10-12T21:20:16.519503Z","iopub.status.idle":"2024-10-12T21:20:29.455514Z","shell.execute_reply.started":"2024-10-12T21:20:16.519467Z","shell.execute_reply":"2024-10-12T21:20:29.454691Z"},"trusted":true},"outputs":[],"execution_count":1},{"cell_type":"code","source":"from tensorflow.keras import mixed_precision\npolicy = mixed_precision.Policy('mixed_float16')\nmixed_precision.set_global_policy(policy)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-12T21:21:04.119445Z","iopub.execute_input":"2024-10-12T21:21:04.119844Z","iopub.status.idle":"2024-10-12T21:21:04.124584Z","shell.execute_reply.started":"2024-10-12T21:21:04.119778Z","shell.execute_reply":"2024-10-12T21:21:04.123555Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/cleaned-amazon-reviews/cleaned_amazon_reviews.csv')\ndata = data.drop(columns=['Title', 'Review'])\n","metadata":{"execution":{"iopub.status.busy":"2024-10-12T21:21:07.792675Z","iopub.execute_input":"2024-10-12T21:21:07.793554Z","iopub.status.idle":"2024-10-12T21:21:08.088545Z","shell.execute_reply.started":"2024-10-12T21:21:07.793510Z","shell.execute_reply":"2024-10-12T21:21:08.087762Z"},"trusted":true},"outputs":[],"execution_count":4},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2024-10-12T21:21:13.084551Z","iopub.execute_input":"2024-10-12T21:21:13.084934Z","iopub.status.idle":"2024-10-12T21:21:13.098864Z","shell.execute_reply.started":"2024-10-12T21:21:13.084897Z","shell.execute_reply":"2024-10-12T21:21:13.097858Z"},"trusted":true},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"   Sentiment                                     Cleaned_Review\n0          0  vietnam veteran one tour enlisted one tour off...\n1          1  found book informative helpful however title b...\n2          0  movie certainly good others however biggest pr...\n3          0  looking forward film actually waited thanksgiv...\n4          0  son read first book disappointed rude lots hat...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sentiment</th>\n      <th>Cleaned_Review</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>vietnam veteran one tour enlisted one tour off...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>found book informative helpful however title b...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>movie certainly good others however biggest pr...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>looking forward film actually waited thanksgiv...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>son read first book disappointed rude lots hat...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"max_features = 5000     # Number of words to consider as features\nmaxlen = 150            # Cut texts after this number of words (reduced for memory efficiency)\nembedding_dim = 50      # Dimension of the embedding vector\nlatent_dim = 100        # Latent space dimension for GAN","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-12T21:21:46.582151Z","iopub.execute_input":"2024-10-12T21:21:46.582768Z","iopub.status.idle":"2024-10-12T21:21:46.587235Z","shell.execute_reply.started":"2024-10-12T21:21:46.582730Z","shell.execute_reply":"2024-10-12T21:21:46.586263Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"df=data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-12T21:21:48.876685Z","iopub.execute_input":"2024-10-12T21:21:48.877541Z","iopub.status.idle":"2024-10-12T21:21:48.881343Z","shell.execute_reply.started":"2024-10-12T21:21:48.877503Z","shell.execute_reply":"2024-10-12T21:21:48.880396Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# data=data.drop(columns=['Title','Review'])","metadata":{"execution":{"iopub.status.busy":"2024-10-12T18:38:07.557685Z","iopub.execute_input":"2024-10-12T18:38:07.558592Z","iopub.status.idle":"2024-10-12T18:38:07.568470Z","shell.execute_reply.started":"2024-10-12T18:38:07.558549Z","shell.execute_reply":"2024-10-12T18:38:07.567585Z"},"trusted":true},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# data.head()","metadata":{"execution":{"iopub.status.busy":"2024-10-12T18:38:10.243034Z","iopub.execute_input":"2024-10-12T18:38:10.243411Z","iopub.status.idle":"2024-10-12T18:38:10.252978Z","shell.execute_reply.started":"2024-10-12T18:38:10.243376Z","shell.execute_reply":"2024-10-12T18:38:10.252045Z"},"trusted":true},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"   Sentiment                                     Cleaned_Review\n0          0  vietnam veteran one tour enlisted one tour off...\n1          1  found book informative helpful however title b...\n2          0  movie certainly good others however biggest pr...\n3          0  looking forward film actually waited thanksgiv...\n4          0  son read first book disappointed rude lots hat...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sentiment</th>\n      <th>Cleaned_Review</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>vietnam veteran one tour enlisted one tour off...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>found book informative helpful however title b...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>movie certainly good others however biggest pr...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>looking forward film actually waited thanksgiv...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>son read first book disappointed rude lots hat...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"# max_features = 5000     # Number of words to consider as features\n# maxlen = 154            # Cut texts after this number of words\n# embedding_dim = 50      # Dimension of the embedding vector\n# latent_dim = 100       ","metadata":{"execution":{"iopub.status.busy":"2024-10-12T18:38:36.247732Z","iopub.execute_input":"2024-10-12T18:38:36.248668Z","iopub.status.idle":"2024-10-12T18:38:36.253608Z","shell.execute_reply.started":"2024-10-12T18:38:36.248604Z","shell.execute_reply":"2024-10-12T18:38:36.251995Z"},"trusted":true},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# Tokenizer and sequence preparation\ntokenizer = Tokenizer(num_words=max_features)\ntokenizer.fit_on_texts(data.Cleaned_Review)\nsequences = tokenizer.texts_to_sequences(data.Cleaned_Review)\nword_index = tokenizer.word_index\nint_to_word = {i: word for word, i in word_index.items()}","metadata":{"execution":{"iopub.status.busy":"2024-10-12T21:22:26.046041Z","iopub.execute_input":"2024-10-12T21:22:26.047082Z","iopub.status.idle":"2024-10-12T21:22:27.484022Z","shell.execute_reply.started":"2024-10-12T21:22:26.046963Z","shell.execute_reply":"2024-10-12T21:22:27.483236Z"},"trusted":true},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# Padding sequences\nx_data = pad_sequences(sequences, maxlen=maxlen)\nx_data = x_data[:1500]  # Limiting data for faster testing","metadata":{"execution":{"iopub.status.busy":"2024-10-12T21:22:48.914564Z","iopub.execute_input":"2024-10-12T21:22:48.915310Z","iopub.status.idle":"2024-10-12T21:22:49.031589Z","shell.execute_reply.started":"2024-10-12T21:22:48.915267Z","shell.execute_reply":"2024-10-12T21:22:49.030836Z"},"trusted":true},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# Pre-trained GloVe embeddings (optional)\ndef load_glove_embeddings(file_path, embedding_dim):\n    embeddings_index = {}\n    with open(file_path) as f:\n        for line in f:\n            values = line.split()\n            word = values[0]\n            coefs = np.asarray(values[1:], dtype='float32')\n            embeddings_index[word] = coefs\n    return embeddings_index","metadata":{"execution":{"iopub.status.busy":"2024-10-12T21:23:21.379147Z","iopub.execute_input":"2024-10-12T21:23:21.379782Z","iopub.status.idle":"2024-10-12T21:23:21.385301Z","shell.execute_reply.started":"2024-10-12T21:23:21.379737Z","shell.execute_reply":"2024-10-12T21:23:21.384332Z"},"trusted":true},"outputs":[],"execution_count":10},{"cell_type":"code","source":"embedding_layer = Embedding(input_dim=max_features, output_dim=embedding_dim)","metadata":{"execution":{"iopub.status.busy":"2024-10-12T21:24:38.957333Z","iopub.execute_input":"2024-10-12T21:24:38.958180Z","iopub.status.idle":"2024-10-12T21:24:38.963282Z","shell.execute_reply.started":"2024-10-12T21:24:38.958141Z","shell.execute_reply":"2024-10-12T21:24:38.962247Z"},"trusted":true},"outputs":[],"execution_count":12},{"cell_type":"code","source":"input_sequences = Input(shape=(maxlen,))\nembeddings = embedding_layer(input_sequences)\nembedding_model = Model(inputs=input_sequences, outputs=embeddings)","metadata":{"execution":{"iopub.status.busy":"2024-10-12T21:26:21.546839Z","iopub.execute_input":"2024-10-12T21:26:21.547230Z","iopub.status.idle":"2024-10-12T21:26:22.224438Z","shell.execute_reply.started":"2024-10-12T21:26:21.547194Z","shell.execute_reply":"2024-10-12T21:26:22.223610Z"},"trusted":true},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# Generate embeddings for the input data\nx_train_embed = embedding_model.predict(x_data)","metadata":{"execution":{"iopub.status.busy":"2024-10-12T21:27:30.845343Z","iopub.execute_input":"2024-10-12T21:27:30.846023Z","iopub.status.idle":"2024-10-12T21:27:31.004976Z","shell.execute_reply.started":"2024-10-12T21:27:30.845979Z","shell.execute_reply":"2024-10-12T21:27:31.004156Z"},"trusted":true},"outputs":[{"name":"stdout","text":"\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"# Flatten embeddings\nx_train_embed_flat = x_train_embed.reshape((x_train_embed.shape[0], -1))","metadata":{"execution":{"iopub.status.busy":"2024-10-12T21:28:30.482423Z","iopub.execute_input":"2024-10-12T21:28:30.483105Z","iopub.status.idle":"2024-10-12T21:28:30.487157Z","shell.execute_reply.started":"2024-10-12T21:28:30.483062Z","shell.execute_reply":"2024-10-12T21:28:30.486320Z"},"trusted":true},"outputs":[],"execution_count":18},{"cell_type":"code","source":"# Normalize the embeddings to the range [-1, 1]\nmin_val = x_train_embed_flat.min()\nmax_val = x_train_embed_flat.max()\nx_train_embed_flat = 2 * (x_train_embed_flat - min_val) / (max_val - min_val) - 1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-12T21:28:50.352762Z","iopub.execute_input":"2024-10-12T21:28:50.353504Z","iopub.status.idle":"2024-10-12T21:28:50.908776Z","shell.execute_reply.started":"2024-10-12T21:28:50.353464Z","shell.execute_reply":"2024-10-12T21:28:50.907706Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"def build_generator(latent_dim, output_dim):\n    input_layer = Input(shape=(latent_dim,))\n    x = Dense(256, activation='relu')(input_layer)\n    x = BatchNormalization(momentum=0.8)(x)\n    x = Dense(512, activation='relu')(x)\n    output_layer = Dense(output_dim, activation='tanh')(x)\n    \n    model = Model(input_layer, output_layer)\n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-12T21:30:22.763094Z","iopub.execute_input":"2024-10-12T21:30:22.763819Z","iopub.status.idle":"2024-10-12T21:30:22.769307Z","shell.execute_reply.started":"2024-10-12T21:30:22.763771Z","shell.execute_reply":"2024-10-12T21:30:22.768337Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"# Initialize generator\noutput_dim = x_train_embed_flat.shape[1]\ngenerator = build_generator(latent_dim, output_dim)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-12T21:30:31.630482Z","iopub.execute_input":"2024-10-12T21:30:31.631366Z","iopub.status.idle":"2024-10-12T21:30:31.670753Z","shell.execute_reply.started":"2024-10-12T21:30:31.631324Z","shell.execute_reply":"2024-10-12T21:30:31.669840Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"def build_discriminator(input_dim):\n    input_layer = Input(shape=(input_dim,))\n    x = Dense(512, activation='relu')(input_layer)\n    x = Dropout(0.4)(x)\n    x = Dense(256, activation='relu')(x)\n    x = Dropout(0.4)(x)\n    output_layer = Dense(1, activation='sigmoid')(x)\n    \n    model = Model(input_layer, output_layer)\n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-12T21:31:01.402654Z","iopub.execute_input":"2024-10-12T21:31:01.403025Z","iopub.status.idle":"2024-10-12T21:31:01.408735Z","shell.execute_reply.started":"2024-10-12T21:31:01.402992Z","shell.execute_reply":"2024-10-12T21:31:01.407820Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"# Initialize discriminator\ndiscriminator = build_discriminator(output_dim)\ndiscriminator.compile(optimizer=Adam(0.0002, 0.5, clipvalue=1.0), loss='binary_crossentropy', metrics=['accuracy'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-12T21:31:05.743066Z","iopub.execute_input":"2024-10-12T21:31:05.743697Z","iopub.status.idle":"2024-10-12T21:31:05.793739Z","shell.execute_reply.started":"2024-10-12T21:31:05.743654Z","shell.execute_reply":"2024-10-12T21:31:05.792954Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"discriminator.trainable = False","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-12T21:31:18.473929Z","iopub.execute_input":"2024-10-12T21:31:18.474307Z","iopub.status.idle":"2024-10-12T21:31:18.478989Z","shell.execute_reply.started":"2024-10-12T21:31:18.474272Z","shell.execute_reply":"2024-10-12T21:31:18.477994Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"# GAN model\ngan_input = Input(shape=(latent_dim,))\nfake_samples = generator(gan_input)\ngan_output = discriminator(fake_samples)\ngan = Model(gan_input, gan_output)\ngan.compile(optimizer=Adam(0.0002, 0.5, clipvalue=1.0), loss='binary_crossentropy')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-12T21:31:32.543266Z","iopub.execute_input":"2024-10-12T21:31:32.543652Z","iopub.status.idle":"2024-10-12T21:31:32.564227Z","shell.execute_reply.started":"2024-10-12T21:31:32.543614Z","shell.execute_reply":"2024-10-12T21:31:32.563221Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"# Train GAN\ndef train_gan(generator, discriminator, gan, x_train_embed_flat, epochs=30, batch_size=32):\n    batch_count = x_train_embed_flat.shape[0] // batch_size\n\n    for epoch in range(epochs):\n        for _ in range(batch_count):\n            # Select a random batch of real samples\n            idx = np.random.randint(0, x_train_embed_flat.shape[0], batch_size)\n            real_samples = x_train_embed_flat[idx]\n\n            # Generate fake samples\n            noise = np.random.normal(0, 1, (batch_size, latent_dim))\n            fake_samples = generator.predict(noise, verbose=0)\n\n            # Combine real and fake samples\n            x = np.vstack((real_samples, fake_samples))\n            y = np.vstack((np.ones((batch_size, 1)), np.zeros((batch_size, 1))))\n\n            # Train the discriminator\n            discriminator.trainable = True\n            d_loss = discriminator.train_on_batch(x, y)\n\n            # Train the generator via the GAN\n            noise = np.random.normal(0, 1, (batch_size, latent_dim))\n            y_gen = np.ones((batch_size, 1))\n            discriminator.trainable = False\n            g_loss = gan.train_on_batch(noise, y_gen)\n\n        print(f\"Epoch {epoch+1}/{epochs}, Discriminator Loss: {d_loss[0]}, Generator Loss: {g_loss}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-12T21:31:49.322309Z","iopub.execute_input":"2024-10-12T21:31:49.323164Z","iopub.status.idle":"2024-10-12T21:31:49.331873Z","shell.execute_reply.started":"2024-10-12T21:31:49.323124Z","shell.execute_reply":"2024-10-12T21:31:49.330841Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"# Start training\ntrain_gan(generator, discriminator, gan, x_train_embed_flat, epochs=30, batch_size=32)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-12T21:32:17.949049Z","iopub.execute_input":"2024-10-12T21:32:17.949865Z","iopub.status.idle":"2024-10-12T21:46:33.026603Z","shell.execute_reply.started":"2024-10-12T21:32:17.949826Z","shell.execute_reply":"2024-10-12T21:46:33.025502Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/30, Discriminator Loss: 0.3551475703716278, Generator Loss: [array(0.35514757, dtype=float32), array(0.35514757, dtype=float32), array(0.8206522, dtype=float32)]\nEpoch 2/30, Discriminator Loss: 0.26035553216934204, Generator Loss: [array(0.26035553, dtype=float32), array(0.26035553, dtype=float32), array(0.88383156, dtype=float32)]\nEpoch 3/30, Discriminator Loss: 0.29895466566085815, Generator Loss: [array(0.29895467, dtype=float32), array(0.29895467, dtype=float32), array(0.8633379, dtype=float32)]\nEpoch 4/30, Discriminator Loss: 0.35960111021995544, Generator Loss: [array(0.3596011, dtype=float32), array(0.3596011, dtype=float32), array(0.8207371, dtype=float32)]\nEpoch 5/30, Discriminator Loss: 0.4010169208049774, Generator Loss: [array(0.40101692, dtype=float32), array(0.40101692, dtype=float32), array(0.7908967, dtype=float32)]\nEpoch 6/30, Discriminator Loss: 0.43032458424568176, Generator Loss: [array(0.43032458, dtype=float32), array(0.43032458, dtype=float32), array(0.77043706, dtype=float32)]\nEpoch 7/30, Discriminator Loss: 0.4476054906845093, Generator Loss: [array(0.4476055, dtype=float32), array(0.4476055, dtype=float32), array(0.7607725, dtype=float32)]\nEpoch 8/30, Discriminator Loss: 0.4524766206741333, Generator Loss: [array(0.45247662, dtype=float32), array(0.45247662, dtype=float32), array(0.7643937, dtype=float32)]\nEpoch 9/30, Discriminator Loss: 0.45180851221084595, Generator Loss: [array(0.4518085, dtype=float32), array(0.4518085, dtype=float32), array(0.77090883, dtype=float32)]\nEpoch 10/30, Discriminator Loss: 0.45435017347335815, Generator Loss: [array(0.45435017, dtype=float32), array(0.45435017, dtype=float32), array(0.7711277, dtype=float32)]\nEpoch 11/30, Discriminator Loss: 0.46425774693489075, Generator Loss: [array(0.46425775, dtype=float32), array(0.46425775, dtype=float32), array(0.76735425, dtype=float32)]\nEpoch 12/30, Discriminator Loss: 0.47899168729782104, Generator Loss: [array(0.4789917, dtype=float32), array(0.4789917, dtype=float32), array(0.7577276, dtype=float32)]\nEpoch 13/30, Discriminator Loss: 0.491438627243042, Generator Loss: [array(0.49143863, dtype=float32), array(0.49143863, dtype=float32), array(0.74785745, dtype=float32)]\nEpoch 14/30, Discriminator Loss: 0.5012645125389099, Generator Loss: [array(0.5012645, dtype=float32), array(0.5012645, dtype=float32), array(0.74087733, dtype=float32)]\nEpoch 15/30, Discriminator Loss: 0.5084332823753357, Generator Loss: [array(0.5084333, dtype=float32), array(0.5084333, dtype=float32), array(0.7349411, dtype=float32)]\nEpoch 16/30, Discriminator Loss: 0.5155139565467834, Generator Loss: [array(0.51551396, dtype=float32), array(0.51551396, dtype=float32), array(0.72981066, dtype=float32)]\nEpoch 17/30, Discriminator Loss: 0.5218096971511841, Generator Loss: [array(0.5218097, dtype=float32), array(0.5218097, dtype=float32), array(0.7237652, dtype=float32)]\nEpoch 18/30, Discriminator Loss: 0.5303414463996887, Generator Loss: [array(0.53034145, dtype=float32), array(0.53034145, dtype=float32), array(0.7162779, dtype=float32)]\nEpoch 19/30, Discriminator Loss: 0.5377941727638245, Generator Loss: [array(0.5377942, dtype=float32), array(0.5377942, dtype=float32), array(0.70950735, dtype=float32)]\nEpoch 20/30, Discriminator Loss: 0.544357419013977, Generator Loss: [array(0.5443574, dtype=float32), array(0.5443574, dtype=float32), array(0.7033288, dtype=float32)]\nEpoch 21/30, Discriminator Loss: 0.5407605171203613, Generator Loss: [array(0.5407605, dtype=float32), array(0.5407605, dtype=float32), array(0.70716876, dtype=float32)]\nEpoch 22/30, Discriminator Loss: 0.5408653616905212, Generator Loss: [array(0.54086536, dtype=float32), array(0.54086536, dtype=float32), array(0.7073864, dtype=float32)]\nEpoch 23/30, Discriminator Loss: 0.5423774719238281, Generator Loss: [array(0.5423775, dtype=float32), array(0.5423775, dtype=float32), array(0.7060639, dtype=float32)]\nEpoch 24/30, Discriminator Loss: 0.5469259023666382, Generator Loss: [array(0.5469259, dtype=float32), array(0.5469259, dtype=float32), array(0.7026014, dtype=float32)]\nEpoch 25/30, Discriminator Loss: 0.5471232533454895, Generator Loss: [array(0.54712325, dtype=float32), array(0.54712325, dtype=float32), array(0.7036141, dtype=float32)]\nEpoch 26/30, Discriminator Loss: 0.5541545748710632, Generator Loss: [array(0.5541546, dtype=float32), array(0.5541546, dtype=float32), array(0.69631845, dtype=float32)]\nEpoch 27/30, Discriminator Loss: 0.5613572001457214, Generator Loss: [array(0.5613572, dtype=float32), array(0.5613572, dtype=float32), array(0.68752515, dtype=float32)]\nEpoch 28/30, Discriminator Loss: 0.5642251372337341, Generator Loss: [array(0.56422514, dtype=float32), array(0.56422514, dtype=float32), array(0.68373936, dtype=float32)]\nEpoch 29/30, Discriminator Loss: 0.5651847124099731, Generator Loss: [array(0.5651847, dtype=float32), array(0.5651847, dtype=float32), array(0.682932, dtype=float32)]\nEpoch 30/30, Discriminator Loss: 0.5694608688354492, Generator Loss: [array(0.56946087, dtype=float32), array(0.56946087, dtype=float32), array(0.6777627, dtype=float32)]\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"batch_size = 32\nfake_samples = generator.predict(np.random.normal(0, 1, (batch_size, latent_dim)))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-12T21:46:57.493256Z","iopub.execute_input":"2024-10-12T21:46:57.493659Z","iopub.status.idle":"2024-10-12T21:46:57.550847Z","shell.execute_reply.started":"2024-10-12T21:46:57.493620Z","shell.execute_reply":"2024-10-12T21:46:57.549971Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"real_samples = x_train_embed_flat[:batch_size]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-12T21:47:01.934704Z","iopub.execute_input":"2024-10-12T21:47:01.935105Z","iopub.status.idle":"2024-10-12T21:47:01.939636Z","shell.execute_reply.started":"2024-10-12T21:47:01.935067Z","shell.execute_reply":"2024-10-12T21:47:01.938572Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"# Combine real and fake samples\nx = np.vstack((real_samples, fake_samples))\ny_true = np.vstack((np.ones((batch_size, 1)), np.zeros((batch_size, 1))))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-12T21:47:09.102485Z","iopub.execute_input":"2024-10-12T21:47:09.103180Z","iopub.status.idle":"2024-10-12T21:47:09.108409Z","shell.execute_reply.started":"2024-10-12T21:47:09.103130Z","shell.execute_reply":"2024-10-12T21:47:09.107455Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"# Get predictions from discriminator\ny_pred = discriminator.predict(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-12T21:47:58.069739Z","iopub.execute_input":"2024-10-12T21:47:58.070130Z","iopub.status.idle":"2024-10-12T21:47:58.288623Z","shell.execute_reply.started":"2024-10-12T21:47:58.070097Z","shell.execute_reply":"2024-10-12T21:47:58.287674Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step  \n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"# Threshold predictions\ny_pred_class = (y_pred > 0.5).astype(int)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-12T21:48:03.357181Z","iopub.execute_input":"2024-10-12T21:48:03.358044Z","iopub.status.idle":"2024-10-12T21:48:03.365489Z","shell.execute_reply.started":"2024-10-12T21:48:03.357989Z","shell.execute_reply":"2024-10-12T21:48:03.364543Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"# Calculate accuracy\naccuracy = np.mean(y_pred_class == y_true)\nprint(f\"Discriminator Accuracy: {accuracy * 100:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-12T21:48:11.997286Z","iopub.execute_input":"2024-10-12T21:48:11.997675Z","iopub.status.idle":"2024-10-12T21:48:12.003072Z","shell.execute_reply.started":"2024-10-12T21:48:11.997639Z","shell.execute_reply":"2024-10-12T21:48:12.002201Z"}},"outputs":[{"name":"stdout","text":"Discriminator Accuracy: 50.00%\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"# Generate synthetic text from the Generator's embeddings\ndef get_closest_token(embedding, word_index, embedding_matrix):\n    similarities = np.dot(embedding_matrix, embedding) / (np.linalg.norm(embedding_matrix, axis=1) * np.linalg.norm(embedding))\n    closest_token = np.argmax(similarities)\n    return closest_token","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-12T21:48:23.272986Z","iopub.execute_input":"2024-10-12T21:48:23.273691Z","iopub.status.idle":"2024-10-12T21:48:23.278920Z","shell.execute_reply.started":"2024-10-12T21:48:23.273647Z","shell.execute_reply":"2024-10-12T21:48:23.277953Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"# Generate synthetic text\nnoise = np.random.normal(0, 1, (1, latent_dim))\ngenerated_sample = generator.predict(noise)\ngenerated_sample = generated_sample.reshape((maxlen, embedding_dim))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-12T21:48:35.223431Z","iopub.execute_input":"2024-10-12T21:48:35.223854Z","iopub.status.idle":"2024-10-12T21:48:35.484549Z","shell.execute_reply.started":"2024-10-12T21:48:35.223786Z","shell.execute_reply":"2024-10-12T21:48:35.483603Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step\n","output_type":"stream"}],"execution_count":37},{"cell_type":"code","source":"# Define an embedding layer\nembedding_layer = Embedding(input_dim=max_features, output_dim=embedding_dim)\nembedding_layer.build((None,))  # This ensures the embedding matrix is created\nembedding_matrix = embedding_layer.get_weights()[0]  # This is the actual matrix","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-12T21:49:23.597809Z","iopub.execute_input":"2024-10-12T21:49:23.598471Z","iopub.status.idle":"2024-10-12T21:49:23.610868Z","shell.execute_reply.started":"2024-10-12T21:49:23.598428Z","shell.execute_reply":"2024-10-12T21:49:23.610043Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"generated_text = []\nfor embedding in generated_sample:\n    token_index = get_closest_token(embedding, word_index, embedding_matrix)\n    word = int_to_word.get(token_index, '?')\n    generated_text.append(word)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-12T21:49:38.166309Z","iopub.execute_input":"2024-10-12T21:49:38.167045Z","iopub.status.idle":"2024-10-12T21:49:38.262896Z","shell.execute_reply.started":"2024-10-12T21:49:38.167000Z","shell.execute_reply":"2024-10-12T21:49:38.261550Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"# Join the generated words into a sentence\ngenerated_sentence = ' '.join(generated_text)\nprint(\"Generated sentence: \", generated_sentence)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-12T21:49:46.404266Z","iopub.execute_input":"2024-10-12T21:49:46.404897Z","iopub.status.idle":"2024-10-12T21:49:46.409951Z","shell.execute_reply.started":"2024-10-12T21:49:46.404857Z","shell.execute_reply":"2024-10-12T21:49:46.408982Z"}},"outputs":[{"name":"stdout","text":"Generated sentence:  meditation meditation meditation zipper meditation bag meditation meditation meditation meditation zipper meditation meditation meditation meditation struggle meditation meditation bag bag bag bag meditation meditation inside bag bag meditation bag struggle struggle meditation beast bag meditation meditation meditation inside beast meditation zipper bag brutal meditation meditation meditation meditation zipper zipper meditation bag meditation struggle bag meditation meditation meditation bag zipper meditation bag meditation meditation bag meditation zipper meditation meditation meditation bag zipper meditation meditation meditation bag meditation zipper meditation meditation meditation meditation bag meditation meditation meditation meditation jess zipper inside meditation meditation inside struggle bag bag violence meditation bag bag struggle bag storage meditation inside bag meditation difficulty zipper bag meditation meditation struggle lacks meditation zipper bag meditation happy zipper materials meditation meditation bag meditation ruined bag bag silent inside difficulty remix zipper vocabulary bag storage timer aspects dummies lacks right raise latch setting mechanics free primarily jams opener everybody promises\n","output_type":"stream"}],"execution_count":41},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define an embedding layer\nembedding_layer = Embedding(input_dim=max_features, output_dim=embedding_dim, input_length=maxlen)\n\n# Create a model to transform word indices to embeddings\ninput_sequences = Input(shape=(maxlen,))\nembeddings = embedding_layer(input_sequences)\nembedding_model = Model(inputs=input_sequences, outputs=embeddings)\n\n# Get embeddings for the training data\nx_train_embed = embedding_model.predict(x_data)\n\n\n# Get the embedding matrix from the embedding layer\nembedding_matrix = embedding_layer.get_weights()[0]  # This is the actual matrix\n\n# Example usage: Get embedding vector for a specific word index\nword_index = 5  # Example word index\nembedding_vector = embedding_matrix[word_index]","metadata":{"execution":{"iopub.status.busy":"2024-10-12T18:39:55.861812Z","iopub.execute_input":"2024-10-12T18:39:55.862843Z","iopub.status.idle":"2024-10-12T18:39:56.178967Z","shell.execute_reply.started":"2024-10-12T18:39:55.862801Z","shell.execute_reply":"2024-10-12T18:39:56.177901Z"},"trusted":true},"outputs":[{"name":"stdout","text":"\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"# Flatten the embeddings to create a feature vector\nx_train_embed_flat = x_train_embed.reshape((x_train_embed.shape[0], -1))\n\n# Normalize the embeddings to the range [-1, 1]\nmin_val = x_train_embed_flat.min()\nmax_val = x_train_embed_flat.max()\nif max_val - min_val == 0:\n    max_val = min_val + 1  # Avoid division by zero\nx_train_embed_flat = 2 * (x_train_embed_flat - min_val) / (max_val - min_val) - 1\n","metadata":{"execution":{"iopub.status.busy":"2024-10-12T18:40:00.478854Z","iopub.execute_input":"2024-10-12T18:40:00.479894Z","iopub.status.idle":"2024-10-12T18:40:00.529564Z","shell.execute_reply.started":"2024-10-12T18:40:00.479848Z","shell.execute_reply":"2024-10-12T18:40:00.528512Z"},"trusted":true},"outputs":[],"execution_count":22},{"cell_type":"code","source":"def build_generator(latent_dim, output_dim):\n    model = Sequential()\n    model.add(Dense(256, activation='relu', input_dim=latent_dim))\n    model.add(BatchNormalization(momentum=0.8))\n    model.add(Dense(512, activation='relu'))\n    model.add(Dense(output_dim, activation='tanh'))\n    return model\n    \n# Initialize the generator\noutput_dim = x_train_embed_flat.shape[1]\ngenerator = build_generator(latent_dim, output_dim)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-12T18:40:03.279062Z","iopub.execute_input":"2024-10-12T18:40:03.279461Z","iopub.status.idle":"2024-10-12T18:40:03.337502Z","shell.execute_reply.started":"2024-10-12T18:40:03.279424Z","shell.execute_reply":"2024-10-12T18:40:03.336466Z"},"trusted":true},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"def build_discriminator(input_dim):\n    model = Sequential()\n    model.add(Dense(512, activation='relu', input_dim=input_dim))\n    model.add(Dropout(0.4))\n    model.add(Dense(256, activation='relu'))\n    model.add(Dropout(0.4))\n    model.add(Dense(1, activation='sigmoid'))\n    return model\n\n# Initialize the discriminator\ndiscriminator = build_discriminator(output_dim)\ndiscriminator.compile(optimizer=Adam(0.0002, 0.5), loss='binary_crossentropy', metrics=['accuracy'])\n","metadata":{"execution":{"iopub.status.busy":"2024-10-12T18:40:27.677272Z","iopub.execute_input":"2024-10-12T18:40:27.678042Z","iopub.status.idle":"2024-10-12T18:40:27.737773Z","shell.execute_reply.started":"2024-10-12T18:40:27.677987Z","shell.execute_reply":"2024-10-12T18:40:27.736973Z"},"trusted":true},"outputs":[],"execution_count":24},{"cell_type":"code","source":"# Make the discriminator untrainable when training the GAN\ndiscriminator.trainable = False\n\n# Input for the GAN\ngan_input = Input(shape=(latent_dim,))\n# The generator produces fake samples\nfake_samples = generator(gan_input)\n# The discriminator evaluates the fake samples\ngan_output = discriminator(fake_samples)\n# Define the GAN model\ngan = Model(gan_input, gan_output)\ngan.compile(optimizer=Adam(0.0002, 0.5), loss='binary_crossentropy')","metadata":{"execution":{"iopub.status.busy":"2024-10-12T18:40:27.749366Z","iopub.execute_input":"2024-10-12T18:40:27.749678Z","iopub.status.idle":"2024-10-12T18:40:27.763426Z","shell.execute_reply.started":"2024-10-12T18:40:27.749645Z","shell.execute_reply":"2024-10-12T18:40:27.762450Z"},"trusted":true},"outputs":[],"execution_count":25},{"cell_type":"code","source":"def train_gan(generator, discriminator, gan, x_train_embed_flat, epochs=10, batch_size=64):\n    batch_count = x_train_embed_flat.shape[0] // batch_size\n    for epoch in range(epochs):\n        for _ in range(batch_count):\n            # Select a random batch of real samples\n            idx = np.random.randint(0, x_train_embed_flat.shape[0], batch_size)\n            real_samples = x_train_embed_flat[idx]\n\n            # Generate fake samples\n            noise = np.random.normal(0, 1, (batch_size, latent_dim))\n            fake_samples = generator.predict(noise ,verbose=0)\n\n            # Combine real and fake samples\n            x = np.vstack((real_samples, fake_samples))\n            y = np.vstack((np.ones((batch_size, 1)), np.zeros((batch_size, 1))))\n\n            # Train the discriminator\n            discriminator.trainable = True\n            d_loss = discriminator.train_on_batch(x, y)\n\n            # Train the generator via the GAN\n            noise = np.random.normal(0, 1, (batch_size, latent_dim))\n            y_gen = np.ones((batch_size, 1))\n            discriminator.trainable = False\n            g_loss = gan.train_on_batch(noise, y_gen)\n\n        # Print the progress\n        print(f\"Epoch {epoch+1}/{epochs}, Discriminator Loss: {d_loss[0]}, Generator Loss: {g_loss}\")\n\n# Start training\ntrain_gan(generator, discriminator, gan, x_train_embed_flat, epochs=30, batch_size=64)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-12T18:40:27.814727Z","iopub.execute_input":"2024-10-12T18:40:27.815090Z","iopub.status.idle":"2024-10-12T18:46:44.792946Z","shell.execute_reply.started":"2024-10-12T18:40:27.815056Z","shell.execute_reply":"2024-10-12T18:46:44.791932Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Epoch 1/30, Discriminator Loss: 0.5590204000473022, Generator Loss: [array(0.5590204, dtype=float32), array(0.5590204, dtype=float32), array(0.64504075, dtype=float32)]\nEpoch 2/30, Discriminator Loss: 0.3605270981788635, Generator Loss: [array(0.3605271, dtype=float32), array(0.3605271, dtype=float32), array(0.8201427, dtype=float32)]\nEpoch 3/30, Discriminator Loss: 0.26730671525001526, Generator Loss: [array(0.26730672, dtype=float32), array(0.26730672, dtype=float32), array(0.87975544, dtype=float32)]\nEpoch 4/30, Discriminator Loss: 0.22021184861660004, Generator Loss: [array(0.22021185, dtype=float32), array(0.22021185, dtype=float32), array(0.90735394, dtype=float32)]\nEpoch 5/30, Discriminator Loss: 0.19923366606235504, Generator Loss: [array(0.19923367, dtype=float32), array(0.19923367, dtype=float32), array(0.91813856, dtype=float32)]\nEpoch 6/30, Discriminator Loss: 0.2524383068084717, Generator Loss: [array(0.2524383, dtype=float32), array(0.2524383, dtype=float32), array(0.8978148, dtype=float32)]\nEpoch 7/30, Discriminator Loss: 0.30471277236938477, Generator Loss: [array(0.30471277, dtype=float32), array(0.30471277, dtype=float32), array(0.86563474, dtype=float32)]\nEpoch 8/30, Discriminator Loss: 0.3301541209220886, Generator Loss: [array(0.33015412, dtype=float32), array(0.33015412, dtype=float32), array(0.84842056, dtype=float32)]\nEpoch 9/30, Discriminator Loss: 0.3489316403865814, Generator Loss: [array(0.34893164, dtype=float32), array(0.34893164, dtype=float32), array(0.8315595, dtype=float32)]\nEpoch 10/30, Discriminator Loss: 0.36534446477890015, Generator Loss: [array(0.36534446, dtype=float32), array(0.36534446, dtype=float32), array(0.81773096, dtype=float32)]\nEpoch 11/30, Discriminator Loss: 0.38058939576148987, Generator Loss: [array(0.3805894, dtype=float32), array(0.3805894, dtype=float32), array(0.8029274, dtype=float32)]\nEpoch 12/30, Discriminator Loss: 0.391100138425827, Generator Loss: [array(0.39110014, dtype=float32), array(0.39110014, dtype=float32), array(0.7948087, dtype=float32)]\nEpoch 13/30, Discriminator Loss: 0.40130120515823364, Generator Loss: [array(0.4013012, dtype=float32), array(0.4013012, dtype=float32), array(0.7867632, dtype=float32)]\nEpoch 14/30, Discriminator Loss: 0.4146076440811157, Generator Loss: [array(0.41460764, dtype=float32), array(0.41460764, dtype=float32), array(0.7759123, dtype=float32)]\nEpoch 15/30, Discriminator Loss: 0.42119234800338745, Generator Loss: [array(0.42119235, dtype=float32), array(0.42119235, dtype=float32), array(0.77235055, dtype=float32)]\nEpoch 16/30, Discriminator Loss: 0.4294818043708801, Generator Loss: [array(0.4294818, dtype=float32), array(0.4294818, dtype=float32), array(0.7674083, dtype=float32)]\nEpoch 17/30, Discriminator Loss: 0.43408846855163574, Generator Loss: [array(0.43408847, dtype=float32), array(0.43408847, dtype=float32), array(0.76734334, dtype=float32)]\nEpoch 18/30, Discriminator Loss: 0.43697047233581543, Generator Loss: [array(0.43697047, dtype=float32), array(0.43697047, dtype=float32), array(0.76764417, dtype=float32)]\nEpoch 19/30, Discriminator Loss: 0.4383827745914459, Generator Loss: [array(0.43838277, dtype=float32), array(0.43838277, dtype=float32), array(0.77032685, dtype=float32)]\nEpoch 20/30, Discriminator Loss: 0.4398660957813263, Generator Loss: [array(0.4398661, dtype=float32), array(0.4398661, dtype=float32), array(0.7716542, dtype=float32)]\nEpoch 21/30, Discriminator Loss: 0.4407428503036499, Generator Loss: [array(0.44074285, dtype=float32), array(0.44074285, dtype=float32), array(0.77342135, dtype=float32)]\nEpoch 22/30, Discriminator Loss: 0.4409375488758087, Generator Loss: [array(0.44093755, dtype=float32), array(0.44093755, dtype=float32), array(0.7761086, dtype=float32)]\nEpoch 23/30, Discriminator Loss: 0.44153064489364624, Generator Loss: [array(0.44153064, dtype=float32), array(0.44153064, dtype=float32), array(0.7776908, dtype=float32)]\nEpoch 24/30, Discriminator Loss: 0.44363683462142944, Generator Loss: [array(0.44363683, dtype=float32), array(0.44363683, dtype=float32), array(0.7772589, dtype=float32)]\nEpoch 25/30, Discriminator Loss: 0.4466457962989807, Generator Loss: [array(0.4466458, dtype=float32), array(0.4466458, dtype=float32), array(0.77657604, dtype=float32)]\nEpoch 26/30, Discriminator Loss: 0.45124199986457825, Generator Loss: [array(0.451242, dtype=float32), array(0.451242, dtype=float32), array(0.7746525, dtype=float32)]\nEpoch 27/30, Discriminator Loss: 0.4577676057815552, Generator Loss: [array(0.4577676, dtype=float32), array(0.4577676, dtype=float32), array(0.77095914, dtype=float32)]\nEpoch 28/30, Discriminator Loss: 0.4650663435459137, Generator Loss: [array(0.46506634, dtype=float32), array(0.46506634, dtype=float32), array(0.7652732, dtype=float32)]\nEpoch 29/30, Discriminator Loss: 0.4744977355003357, Generator Loss: [array(0.47449774, dtype=float32), array(0.47449774, dtype=float32), array(0.75739086, dtype=float32)]\nEpoch 30/30, Discriminator Loss: 0.48122715950012207, Generator Loss: [array(0.48122716, dtype=float32), array(0.48122716, dtype=float32), array(0.75217396, dtype=float32)]\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"batch_size=64\n# Generate fake samples\nfake_samples = generator.predict(np.random.normal(0, 1, (batch_size, latent_dim)))\n\n# Take some real samples\nreal_samples = x_train_embed_flat[:batch_size]\n\n# Combine real and fake samples\nx = np.vstack((real_samples, fake_samples))\ny_true = np.vstack((np.ones((batch_size, 1)), np.zeros((batch_size, 1))))\n\n# Get the predictions from the discriminator\ny_pred = discriminator.predict(x)\n\n# Threshold predictions (discriminator outputs probabilities)\ny_pred_class = (y_pred > 0.5).astype(int)\n\n# Calculate accuracy\naccuracy = np.mean(y_pred_class == y_true)\n\nprint(f\"Discriminator Accuracy: {accuracy * 100:.2f}%\")\n","metadata":{"execution":{"iopub.status.busy":"2024-10-12T18:49:52.487298Z","iopub.execute_input":"2024-10-12T18:49:52.488069Z","iopub.status.idle":"2024-10-12T18:49:52.786294Z","shell.execute_reply.started":"2024-10-12T18:49:52.488030Z","shell.execute_reply":"2024-10-12T18:49:52.785353Z"},"trusted":true},"outputs":[{"name":"stdout","text":"\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \nDiscriminator Accuracy: 65.62%\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"# Assuming you have a tokenizer and int_to_word dictionary ready\n# tokenizer = your tokenizer used to tokenize the training data\n# int_to_word = a dictionary mapping token indices back to words\n\n# Function to map embedding back to nearest word/token index\ndef get_closest_token(embedding, word_index, embedding_matrix):\n    # Calculate cosine similarity between generated embedding and actual embeddings\n    similarities = np.dot(embedding_matrix, embedding) / (np.linalg.norm(embedding_matrix, axis=1) * np.linalg.norm(embedding))\n    closest_token = np.argmax(similarities)  # Find the index of the most similar embedding\n    return closest_token\n\n# Generate synthetic movie review embeddings\nnoise = np.random.normal(0, 1, (1, latent_dim))\ngenerated_sample = generator.predict(noise)\n\n# Reshape the output to match the (maxlen, embedding_dim)\ngenerated_sample = generated_sample.reshape((maxlen, embedding_dim))\n\n# Load your word embedding matrix (e.g., from a pre-trained model or from training data)\n# embedding_matrix is the matrix where each row corresponds to a word's embedding\n# word_index is the tokenizer's word-to-index mapping (reverse of int_to_word)\n# Assuming embedding_matrix and word_index are already loaded/available\n\ngenerated_text = []\nfor embedding in generated_sample:\n    token_index = get_closest_token(embedding, word_index, embedding_matrix)\n    word = int_to_word.get(token_index, '?')  # Get the word corresponding to the token\n    generated_text.append(word)\n\n# Join the generated words into a sentence\ngenerated_sentence = ' '.join(generated_text)\nprint(\"Generated sentence: \", generated_sentence)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-12T18:50:01.736728Z","iopub.execute_input":"2024-10-12T18:50:01.737639Z","iopub.status.idle":"2024-10-12T18:50:02.151732Z","shell.execute_reply.started":"2024-10-12T18:50:01.737586Z","shell.execute_reply":"2024-10-12T18:50:02.150163Z"},"trusted":true},"outputs":[{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step\nGenerated sentence:  ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? pretentious ? ? ? ? ? bored ? disappointment discovering ? pretentious challenged features furthermore mind small profession accessory ordinary collection enemy tedious techniques spiritual hip\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}